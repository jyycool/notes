## 码表的理解(ASCII,GBK,Unicode,UTF-8等)

在计算机中无论任何数据的传输、存储、持久化，都是以二进制的形式体现的。

那么当我存一个字符的时候，计算机需要持久化到硬盘，或者保存在内存中。这个时候保存在内存、硬盘的数据显然也是二进制的。

那么当我需要从硬盘、内存中取出这些字符，再显示的时候，为什么二进制会变成了字符呢？

这就是码表存在的意义。***码表其实就是一个字符和其对应的二进制相互映射的一张表。***这张表中规定了字符和二进制的映射关系。

计算机存储字符时将字符查询码表，然后存储对应的二进制。计算机取出字符时将二进制查询码表，然后转换成对应的字符显示。 **大致可以这样理解。**然而, 不同的码表所容纳的字符映射也是不同的。

在有些码表中一个字符占用1个字节(byte)，1个字节能表示的范围是-128到127(8bit0 ~ 8bit1)，总共为256 = 2<sup>8</sup>。每一个状态对应一个符号，就是256个符号，从0000000到11111111。而有的码表中一个字符占用2个字节，甚至3个字节，因此能容纳的字符映射也更多。

下面笔者按照自己的理解详细讲述一下不同的码表。

### 1. ASCII码

上个世纪60年代，美国制定了一套字符编码，码表中只有英文大小写字母、数字、美式标点符号等。这套编码被称为ASCII码，一直沿用至今。

ASCII码一共规定了128个字符的编码，比如空格“SPACE”是32（二进制00100000），大写的字母A是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号），只占用了一个字节的后面7位，最前面的1位统一规定为0。

### 2. 非ASCII码

英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用ASCII码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。

但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了é，在希伯来语编码中却代表了字母Gimel (ג)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0—127表示的符号是一样的，不一样的只是128—255的这一段。

至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，***简体中文常见的编码方式是GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示256x256=65536个符号。***

中文编码的问题需要专文讨论，这篇笔记不涉及。这里只指出，虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的Unicode和UTF-8是毫无关系的。

### 3. Unicode

***Unicode 为世界上所有字符都分配了一个唯一的数字编号，这个编号范围从 0x000000 到 0x10FFFF (十六进制)，有 110 多万，每个字符都有一个唯一的 Unicode 编号，这个编号一般写成 16 进制，在前面加上 U+。***例如：“马”的 Unicode 是U+9A6C。

Unicode 就相当于一张表，建立了字符与编号之间的联系

它是一种规定，Unicode 本身只规定了每个字符的数字编号是多少，并没有规定这个编号如何存储。

有的人会说了，那我可以直接把 Unicode 编号直接转换成二进制进行存储，是的，你可以，但是这个就需要人为的规定了，而 Unicode 并没有说这样弄，因为除了你这种直接转换成二进制的方案外，还有其他方案，接下来我们会逐一看到。

***编号怎么对应到二进制表示呢？有多种方案：主要有 UTF-8，UTF-16，UTF-32。***

#### 3.1 UTF-32

先来看简单的 UTF-32

***这个就是字符所对应编号的整数二进制形式，四个字节。这个就是直接转换。*** 比如马的 Unicode 为：U+9A6C，那么直接转化为二进制，它的表示就为：1001 1010 0110 1100。

这里需要说明的是，转换成二进制后计算机存储的问题，我们知道，计算机在存储器中排列字节有两种方式：大端法和小端法，大端法就是将高位字节放到底地址处，比如 0x1234, 计算机用两个字节存储，一个是高位字节 0x12,一个是低位字节 0x34。

UTF-32 用四个字节表示，处理单元为四个字节（一次拿到四个字节进行处理），如果不分大小端的话，那么就会出现解读错误，比如我们一次要处理四个字节 12 34 56 78，这四个字节是表示 0x12 34 56 78 还是表示 0x78 56 34 12？不同的解释最终表示的值不一样。

我们可以根据他们高低字节的存储位置来判断他们所代表的含义，所以在编码方式中有 UTF-32BE 和 UTF-32LE，分别对应大端和小端，来正确地解释多个字节（这里是四个字节）的含义。

#### 3.2 UTF-16

UTF-16 使用变长字节表示

① 对于编号在 U+0000 到 U+FFFF 的字符（常用字符集），直接用两个字节表示。
② 编号在 U+10000 到 U+10FFFF 之间的字符，需要用四个字节表示。

同样，UTF-16 也有字节的顺序问题（大小端），所以就有 UTF-16BE 表示大端，UTF-16LE 表示小端。

#### 3.3 UTF-8

UTF-8 就是使用变长字节表示,顾名思义，就是使用的字节数可变，这个变化是***根据 Unicode 编号的大小有关，编号小的使用的字节就少，编号大的使用的字节就多。使用的字节个数从 1 到 4 个不等。***

UTF-8 的编码规则是：

1. 对于单字节的符号，字节的第一位设为 0，后面的7位为这个符号的 Unicode 码，因此对于英文字母，UTF-8 编码和 ASCII 码是相同的。

2. 对于n字节的符号（n>1）,第一个字节的前 n 位都设为 1，第 n+1 位设为 0，后面字节的前两位一律设为 10，剩下的没有提及的二进制位，全部为这个符号的 Unicode 码 。

举个例子：比如说一个字符的 Unicode 编码是 130，显然按照 UTF-8 的规则一个字节是表示不了它（因为如果是一个字节的话前面的一位必须是 0），所以需要两个字节(n = 2)。

根据规则，第一个字节的前 2 位都设为 1，第 3(2+1) 位设为 0，则第一个字节为：110X XXXX，后面字节的前两位一律设为 10，后面只剩下一个字节，所以后面的字节为：10XX XXXX。

所以它的格式为 110XXXXX 10XXXXXX 。

### 小结

因此，简单点说，Unicode 是为了解决传统的字符编码方案的局限而产生的，它为每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求，这点是ASCII码做不到的。
而UTF-32，UTF-16，UTF-8则是Unicode编码的几种方式。